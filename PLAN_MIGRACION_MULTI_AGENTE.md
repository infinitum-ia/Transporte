# Plan de Migraci√≥n: Arquitectura Multi-Agente con An√°lisis Emocional

**Fecha:** 2026-01-10
**Objetivo:** Migrar de arquitectura LangGraph mono-agente a multi-agente con an√°lisis emocional, validaci√≥n de seguridad y memoria emocional persistente.

---

## 1. RESUMEN EJECUTIVO

### Arquitectura Actual (Mono-Agente)
- **1 agente LLM** (`llm_responder`) que genera respuestas basadas en prompts contextuales
- Flujo lineal: validaciones pre-LLM ‚Üí LLM ‚Üí procesamiento post-LLM
- Context builder con an√°lisis de pol√≠ticas y casos similares

### Arquitectura Propuesta (Multi-Agente)
- **3 agentes LLM especializados:**
  1. **Context & Emotion Manager** (Agente Secundario): Analiza sentimiento, conflicto, personalidad
  2. **The Orchestrator** (Agente Principal): Genera respuestas adaptadas al contexto emocional
  3. **The Guardrail** (Agente de Seguridad): Valida respuestas antes de enviarlas al usuario

- **Memoria emocional persistente**: Historial de estados emocionales del usuario
- **Validaci√≥n en cascada**: El Guardrail puede rechazar y forzar re-generaci√≥n
- **Adaptaci√≥n de personalidad din√°mica**: Balanceado, Simplificado, T√©cnico

---

## 2. CAMBIOS EN EL STATE (ConversationState)

### Archivo: `src/agent/graph/state.py`

**AGREGAR CAMPOS NUEVOS:**

```python
# ========== An√°lisis Emocional y Personalidad ==========
emotional_memory: List[Dict[str, Any]]
"""
Historial de estados emocionales por turno.
Cada entrada: {
    "turn": int,
    "sentiment": str,  # Frustraci√≥n | Incertidumbre | Neutro | Euforia
    "conflict_level": str,  # Bajo | Medio | Alto
    "timestamp": str
}
"""

current_sentiment: Optional[str]
"""Sentimiento actual del usuario: Frustraci√≥n | Incertidumbre | Neutro | Euforia"""

current_conflict_level: Optional[str]
"""Nivel de conflicto actual: Bajo | Medio | Alto"""

personality_mode: str
"""
Modo de personalidad del agente: Balanceado (default) | Simplificado | T√©cnico
- Balanceado: Conversaci√≥n natural est√°ndar
- Simplificado: Lenguaje m√°s simple, evita tecnicismos (se activa con confusi√≥n repetida)
- T√©cnico: Detalles espec√≠ficos, respuestas m√°s informativas
"""

sarcasm_detected: bool
"""Si se detect√≥ sarcasmo en el √∫ltimo mensaje del usuario"""

ambiguity_detected: bool
"""Si se detect√≥ ambig√ºedad en el √∫ltimo mensaje del usuario"""

emotional_validation_required: bool
"""Si el usuario requiere validaci√≥n emocional antes de continuar con datos"""

# ========== Validaci√≥n de Seguridad ==========
safety_validation_status: Optional[str]
"""Estado de validaci√≥n: APPROVED | REJECTED | PENDING"""

safety_rejection_reason: Optional[str]
"""Raz√≥n de rechazo por el Guardrail"""

safety_correction_needed: Optional[str]
"""Correcci√≥n sugerida por el Guardrail"""

validation_attempt_count: int
"""N√∫mero de intentos de validaci√≥n (l√≠mite: 3)"""

safety_issues_detected: List[str]
"""
Lista de problemas detectados por el Guardrail:
- fallo_logico: Datos inconsistentes con Excel
- seguridad: Revelaci√≥n de datos sensibles
- accesibilidad: Lenguaje demasiado complejo
- consistencia: Falta confirmaci√≥n de datos antes de despedida
"""
```

**VALORES POR DEFECTO EN INICIALIZACI√ìN:**

```python
# En langgraph_orchestrator.py o donde se inicialice el state
"emotional_memory": [],
"current_sentiment": "Neutro",
"current_conflict_level": "Bajo",
"personality_mode": "Balanceado",
"sarcasm_detected": False,
"ambiguity_detected": False,
"emotional_validation_required": False,
"safety_validation_status": None,
"safety_rejection_reason": None,
"safety_correction_needed": None,
"validation_attempt_count": 0,
"safety_issues_detected": [],
```

---

## 3. NUEVOS NODOS DEL GRAFO

### 3.1. Context & Emotion Manager (Agente Secundario)

**Archivo a crear:** `src/agent/graph/nodes/context_emotion_analyzer.py`

**Responsabilidad:**
- Analizar el √∫ltimo mensaje del usuario ANTES de que el Orchestrator genere respuesta
- Clasificar sentimiento (Frustraci√≥n, Incertidumbre, Neutro, Euforia)
- Evaluar nivel de conflicto (Bajo, Medio, Alto)
- Sugerir adaptaci√≥n de personalidad (Balanceado, Simplificado, T√©cnico)
- Detectar expresiones no literales (sarcasmo, ambig√ºedad)

**Estructura b√°sica:**

```python
from typing import Dict, Any
import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from src.infrastructure.config.settings import settings
from src.agent.prompts.emotion_analyzer_prompt import build_emotion_analysis_prompt
import logging

logger = logging.getLogger(__name__)

def context_emotion_analyzer(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Agente Secundario: Analiza contexto emocional antes de la respuesta.

    OUTPUT esperado del LLM (JSON):
    {
        "sentiment": "Frustraci√≥n | Incertidumbre | Neutro | Euforia",
        "conflict_level": "Bajo | Medio | Alto",
        "personality_adaptation": "Balanceado | Simplificado | T√©cnico",
        "sarcasm_detected": bool,
        "ambiguity_detected": bool,
        "emotional_validation_required": bool,
        "resolution_strategy": "Validaci√≥n Emocional | Informativa | Directa"
    }
    """

    print(f"\n{'‚îÅ'*80}")
    print(f"üòä [AGENTE A] CONTEXT & EMOTION MANAGER - An√°lisis Emocional")
    print(f"{'‚îÅ'*80}")

    # Obtener √∫ltimo mensaje del usuario
    messages = state.get("messages", [])
    last_user_message = ""
    for msg in reversed(messages):
        if isinstance(msg, dict) and msg.get("role") == "user":
            last_user_message = msg.get("content", "")
            break
        elif hasattr(msg, "type") and msg.type == "human":
            last_user_message = msg.content
            break

    if not last_user_message:
        # Sin mensaje, retornar valores neutros
        state["current_sentiment"] = "Neutro"
        state["current_conflict_level"] = "Bajo"
        state["personality_mode"] = "Balanceado"
        return state

    # Construir prompt de an√°lisis emocional
    emotion_prompt = build_emotion_analysis_prompt(
        last_user_message=last_user_message,
        emotional_history=state.get("emotional_memory", []),
        current_phase=state.get("current_phase", "GREETING")
    )

    # Llamar LLM para an√°lisis
    try:
        llm = ChatOpenAI(
            openai_api_key=settings.OPENAI_API_KEY,
            model=settings.OPENAI_MODEL,
            temperature=0.3,  # M√°s bajo para an√°lisis objetivo
            max_tokens=500,
            response_format={"type": "json_object"}
        )

        llm_messages = [
            SystemMessage(content=emotion_prompt),
            HumanMessage(content=last_user_message)
        ]

        print(f"üß† Analizando emoci√≥n con {settings.OPENAI_MODEL}...")
        response = llm.invoke(llm_messages)
        analysis = json.loads(response.content)

        # Actualizar state con an√°lisis
        state["current_sentiment"] = analysis.get("sentiment", "Neutro")
        state["current_conflict_level"] = analysis.get("conflict_level", "Bajo")
        state["personality_mode"] = analysis.get("personality_adaptation", "Balanceado")
        state["sarcasm_detected"] = analysis.get("sarcasm_detected", False)
        state["ambiguity_detected"] = analysis.get("ambiguity_detected", False)
        state["emotional_validation_required"] = analysis.get("emotional_validation_required", False)

        # Agregar a memoria emocional
        emotional_entry = {
            "turn": state.get("turn_count", 0),
            "sentiment": state["current_sentiment"],
            "conflict_level": state["current_conflict_level"],
            "timestamp": state.get("updated_at", "")
        }
        emotional_memory = state.get("emotional_memory", [])
        emotional_memory.append(emotional_entry)
        state["emotional_memory"] = emotional_memory

        print(f"‚úÖ An√°lisis emocional completado:")
        print(f"   üòä Sentimiento: {state['current_sentiment']}")
        print(f"   ‚ö†Ô∏è  Nivel conflicto: {state['current_conflict_level']}")
        print(f"   üé≠ Modo personalidad: {state['personality_mode']}")
        print(f"   üé™ Sarcasmo: {'S√≠' if state['sarcasm_detected'] else 'No'}")
        print(f"   ‚ùì Ambig√ºedad: {'S√≠' if state['ambiguity_detected'] else 'No'}")
        if state['emotional_validation_required']:
            print(f"   ‚ù§Ô∏è  REQUIERE VALIDACI√ìN EMOCIONAL")
        print(f"{'‚îÅ'*80}\n")

    except Exception as e:
        logger.error(f"Error en an√°lisis emocional: {e}")
        # Valores por defecto en caso de error
        state["current_sentiment"] = "Neutro"
        state["current_conflict_level"] = "Bajo"
        state["personality_mode"] = "Balanceado"

    return state
```

**Archivo de prompts a crear:** `src/agent/prompts/emotion_analyzer_prompt.py`

```python
from typing import List, Dict, Any

def build_emotion_analysis_prompt(
    last_user_message: str,
    emotional_history: List[Dict[str, Any]],
    current_phase: str
) -> str:
    """Construye prompt para an√°lisis emocional del mensaje del usuario"""

    prompt = f"""Eres un Analista de Contexto y Emociones experto en atenci√≥n al cliente.

Tu tarea es analizar el mensaje del usuario y clasificar:

1. **Sentimiento**: Clasifica en una de estas categor√≠as:
   - Frustraci√≥n: Usuario molesto, enojado, impaciente
   - Incertidumbre: Usuario confundido, inseguro, con dudas
   - Neutro: Tono normal, sin emociones marcadas
   - Euforia: Usuario muy contento, agradecido, positivo

2. **Nivel de Conflicto**: Eval√∫a la intensidad del problema:
   - Bajo: Consulta simple, sin problema grave
   - Medio: Problema que requiere atenci√≥n, pero manejable
   - Alto: Problema grave, usuario muy molesto o urgente

3. **Adaptaci√≥n de Personalidad Sugerida**:
   - Modo Simplificado: Si hay confusi√≥n repetida, lenguaje complejo dificulta comprensi√≥n
   - Modo T√©cnico: Si el usuario pide detalles espec√≠ficos, datos precisos
   - Modo Balanceado: Conversaci√≥n est√°ndar (default)

4. **Expresiones no literales**:
   - Sarcasmo: ¬øEl usuario usa sarcasmo o iron√≠a?
   - Ambig√ºedad: ¬øEl mensaje es ambiguo o poco claro?

5. **Estrategia de Resoluci√≥n**:
   - Validaci√≥n Emocional: Si hay enojo/frustraci√≥n, usar frases emp√°ticas ANTES de dar datos
   - Informativa: Dar informaci√≥n directa y clara
   - Directa: Respuesta breve y concisa

**Fase actual de la conversaci√≥n:** {current_phase}

**Historial emocional reciente:**
"""

    if emotional_history:
        for entry in emotional_history[-3:]:  # √öltimos 3 turnos
            prompt += f"\n- Turno {entry['turn']}: {entry['sentiment']} (Conflicto: {entry['conflict_level']})"
    else:
        prompt += "\n(Sin historial previo)"

    prompt += """

**IMPORTANTE:**
- Si el usuario repite "¬øC√≥mo?" o "¬øQu√©?" ‚Üí Sugiere Modo Simplificado
- Si el usuario muestra frustraci√≥n ‚Üí Requiere Validaci√≥n Emocional
- Si el usuario pide detalles t√©cnicos ‚Üí Sugiere Modo T√©cnico

**OUTPUT (JSON obligatorio):**
```json
{
  "sentiment": "Frustraci√≥n | Incertidumbre | Neutro | Euforia",
  "conflict_level": "Bajo | Medio | Alto",
  "personality_adaptation": "Balanceado | Simplificado | T√©cnico",
  "sarcasm_detected": true/false,
  "ambiguity_detected": true/false,
  "emotional_validation_required": true/false,
  "resolution_strategy": "Validaci√≥n Emocional | Informativa | Directa"
}
```
"""

    return prompt
```

---

### 3.2. The Orchestrator (Agente Principal)

**Archivo a crear:** `src/agent/graph/nodes/orchestrator.py`

**Responsabilidad:**
- Generar la respuesta del agente bas√°ndose en:
  - An√°lisis emocional del Agente Secundario
  - Contexto de pol√≠ticas y casos (del context_builder)
  - Fase actual de la conversaci√≥n
  - Datos ya conocidos del paciente/servicio
- Decidir el cambio de fase (next_phase)
- Aplicar estrategias de resoluci√≥n seg√∫n el estado emocional

**Diferencias con `llm_responder` actual:**
- Recibe contexto emocional como input adicional
- Adapta tono y estilo seg√∫n `personality_mode`
- Aplica validaci√≥n emocional si `emotional_validation_required = True`
- No repite datos ya confirmados

**Estructura b√°sica:**

```python
from typing import Dict, Any
import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from src.infrastructure.config.settings import settings
from src.agent.prompts.orchestrator_prompt import build_orchestrator_prompt
import logging

logger = logging.getLogger(__name__)

def orchestrator(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Agente Principal (The Orchestrator): Genera respuesta adaptada al contexto emocional.

    INPUT del state:
    - llm_system_prompt (del context_builder)
    - current_sentiment, current_conflict_level, personality_mode (del emotion_analyzer)
    - emotional_validation_required

    OUTPUT (JSON):
    {
        "agent_response": str,
        "next_phase": str,
        "requires_escalation": bool,
        "extracted": {...}
    }
    """

    print(f"\n{'‚îÅ'*80}")
    print(f"üé≠ [AGENTE B] THE ORCHESTRATOR - Generando Respuesta Contextual")
    print(f"{'‚îÅ'*80}")

    # Obtener contexto emocional
    sentiment = state.get("current_sentiment", "Neutro")
    conflict_level = state.get("current_conflict_level", "Bajo")
    personality_mode = state.get("personality_mode", "Balanceado")
    emotional_validation_required = state.get("emotional_validation_required", False)

    print(f"   üòä Sentimiento: {sentiment}")
    print(f"   ‚ö†Ô∏è  Conflicto: {conflict_level}")
    print(f"   üé≠ Personalidad: {personality_mode}")
    if emotional_validation_required:
        print(f"   ‚ù§Ô∏è  VALIDACI√ìN EMOCIONAL ACTIVADA")

    # Obtener prompt base del context_builder
    base_prompt = state.get("llm_system_prompt", "")

    # Construir prompt enriquecido con contexto emocional
    orchestrator_prompt = build_orchestrator_prompt(
        base_prompt=base_prompt,
        sentiment=sentiment,
        conflict_level=conflict_level,
        personality_mode=personality_mode,
        emotional_validation_required=emotional_validation_required,
        current_phase=state.get("current_phase", "GREETING"),
        safety_correction=state.get("safety_correction_needed")  # Si el Guardrail rechaz√≥
    )

    # Obtener √∫ltimo mensaje del usuario
    messages = state.get("messages", [])
    last_user_message = ""
    for msg in reversed(messages):
        if isinstance(msg, dict) and msg.get("role") == "user":
            last_user_message = msg.get("content", "")
            break
        elif hasattr(msg, "type") and msg.type == "human":
            last_user_message = msg.content
            break

    if not last_user_message:
        logger.warning("No user message found")
        state["agent_response"] = "Disculpe, no entend√≠. ¬øMe puede repetir?"
        state["next_phase"] = state.get("current_phase", "GREETING")
        return state

    try:
        # LLM call
        llm = ChatOpenAI(
            openai_api_key=settings.OPENAI_API_KEY,
            model=settings.OPENAI_MODEL,
            temperature=settings.OPENAI_TEMPERATURE,
            max_tokens=settings.OPENAI_MAX_TOKENS,
            response_format={"type": "json_object"}
        )

        llm_messages = [
            SystemMessage(content=orchestrator_prompt),
            HumanMessage(content=last_user_message)
        ]

        print(f"\nüß† Generando respuesta con {settings.OPENAI_MODEL}...")
        print(f"   Prompt: ~{len(orchestrator_prompt.split())} palabras")

        response = llm.invoke(llm_messages)
        llm_output = json.loads(response.content)

        # Actualizar state
        state["agent_response"] = llm_output.get("agent_response", "")
        state["next_phase"] = llm_output.get("next_phase", state.get("current_phase"))
        state["requires_escalation"] = llm_output.get("requires_escalation", False)
        state["extracted_data"] = llm_output.get("extracted", {})
        state["_llm_raw_output"] = response.content

        print(f"\n‚úÖ [AGENTE B] Respuesta generada:")
        print(f"   üí¨ '{state['agent_response'][:100]}...'")
        print(f"   üîÑ Fase: {state.get('current_phase')} ‚Üí {state['next_phase']}")
        print(f"{'‚îÅ'*80}\n")

    except Exception as e:
        logger.error(f"Error en orchestrator: {e}")
        state["agent_response"] = "Disculpe, hubo un problema t√©cnico."
        state["next_phase"] = state.get("current_phase", "GREETING")

    return state
```

**Archivo de prompts a crear:** `src/agent/prompts/orchestrator_prompt.py`

```python
def build_orchestrator_prompt(
    base_prompt: str,
    sentiment: str,
    conflict_level: str,
    personality_mode: str,
    emotional_validation_required: bool,
    current_phase: str,
    safety_correction: str = None
) -> str:
    """Enriquece el prompt base con adaptaciones emocionales"""

    # Comenzar con el prompt base (ya tiene contexto de pol√≠ticas, casos, datos)
    enriched_prompt = base_prompt

    # Agregar secci√≥n de ADAPTACI√ìN EMOCIONAL
    enriched_prompt += f"\n\n{'='*80}\n"
    enriched_prompt += "## ADAPTACI√ìN EMOCIONAL Y PERSONALIDAD\n"
    enriched_prompt += f"{'='*80}\n\n"

    enriched_prompt += f"**Sentimiento del usuario detectado:** {sentiment}\n"
    enriched_prompt += f"**Nivel de conflicto:** {conflict_level}\n"
    enriched_prompt += f"**Modo de personalidad sugerido:** {personality_mode}\n\n"

    # Instrucciones seg√∫n sentimiento
    if sentiment == "Frustraci√≥n":
        enriched_prompt += "‚ö†Ô∏è **USUARIO FRUSTRADO/ENOJADO:**\n"
        enriched_prompt += "- PRIORIDAD: Validaci√≥n emocional ANTES de dar datos\n"
        enriched_prompt += "- Usa frases emp√°ticas: 'Entiendo su frustraci√≥n, Sr./Sra. {nombre}...'\n"
        enriched_prompt += "- NO des informaci√≥n t√©cnica de inmediato\n"
        enriched_prompt += "- Primero valida la emoci√≥n, luego ofrece soluci√≥n\n\n"

    elif sentiment == "Incertidumbre":
        enriched_prompt += "‚ùì **USUARIO CON DUDAS/CONFUSI√ìN:**\n"
        enriched_prompt += "- Usa lenguaje claro y simple\n"
        enriched_prompt += "- Confirma comprensi√≥n: '¬øLe qued√≥ claro?' o '¬øTiene alguna duda?'\n"
        enriched_prompt += "- Repite informaci√≥n importante de forma diferente\n\n"

    elif sentiment == "Euforia":
        enriched_prompt += "üòä **USUARIO POSITIVO/AGRADECIDO:**\n"
        enriched_prompt += "- Mant√©n tono amable pero profesional\n"
        enriched_prompt += "- Puedes ser m√°s c√°lido en el trato\n\n"

    # Instrucciones seg√∫n conflicto
    if conflict_level == "Alto":
        enriched_prompt += "üö® **CONFLICTO ALTO:**\n"
        enriched_prompt += "- Considera escalaci√≥n a EPS si el problema est√° fuera de alcance\n"
        enriched_prompt += "- Ofrece alternativas concretas\n"
        enriched_prompt += "- No prometas lo que no puedes cumplir\n\n"

    # Instrucciones seg√∫n modo de personalidad
    if personality_mode == "Simplificado":
        enriched_prompt += "üî§ **MODO SIMPLIFICADO ACTIVADO:**\n"
        enriched_prompt += "- Evita tecnicismos\n"
        enriched_prompt += "- Usa frases cortas y directas\n"
        enriched_prompt += "- Explica paso a paso si es necesario\n\n"

    elif personality_mode == "T√©cnico":
        enriched_prompt += "üî¨ **MODO T√âCNICO ACTIVADO:**\n"
        enriched_prompt += "- El usuario quiere detalles espec√≠ficos\n"
        enriched_prompt += "- Proporciona informaci√≥n precisa (fechas, horas, direcciones exactas)\n"
        enriched_prompt += "- Puedes usar t√©rminos m√°s formales\n\n"

    # Si requiere validaci√≥n emocional
    if emotional_validation_required:
        enriched_prompt += "‚ù§Ô∏è **VALIDACI√ìN EMOCIONAL REQUERIDA:**\n"
        enriched_prompt += "ANTES de dar cualquier dato, usa una frase de validaci√≥n:\n"
        enriched_prompt += "Ejemplos:\n"
        enriched_prompt += "- 'Entiendo su preocupaci√≥n, Sr./Sra. {nombre}, perm√≠tame ayudarle...'\n"
        enriched_prompt += "- 'Comprendo lo frustrante que puede ser esto...'\n"
        enriched_prompt += "- 'Tiene toda la raz√≥n en sentirse as√≠, vamos a resolverlo...'\n\n"

    # Si el Guardrail rechaz√≥ la respuesta anterior
    if safety_correction:
        enriched_prompt += "üõ°Ô∏è **CORRECCI√ìN DE SEGURIDAD:**\n"
        enriched_prompt += f"Tu respuesta anterior fue rechazada por: {safety_correction}\n"
        enriched_prompt += "Por favor, genera una nueva respuesta corrigiendo este problema.\n\n"

    # Recordatorio final
    enriched_prompt += f"{'='*80}\n"
    enriched_prompt += "## REGLAS CR√çTICAS\n"
    enriched_prompt += f"{'='*80}\n\n"
    enriched_prompt += "1. NO repitas datos ya confirmados en turnos anteriores\n"
    enriched_prompt += "2. Si el usuario se identifica correctamente ‚Üí avanza de fase\n"
    enriched_prompt += "3. Si es menor de edad ‚Üí activa protocolo 'Persona Autorizada'\n"
    enriched_prompt += f"4. Fase actual: {current_phase}\n"
    enriched_prompt += "5. Tu respuesta debe ser en formato JSON con:\n"
    enriched_prompt += "   - agent_response (str)\n"
    enriched_prompt += "   - next_phase (str)\n"
    enriched_prompt += "   - requires_escalation (bool)\n"
    enriched_prompt += "   - extracted (dict con datos extra√≠dos)\n"

    return enriched_prompt
```

---

### 3.3. The Guardrail (Agente de Seguridad)

**Archivo a crear:** `src/agent/graph/nodes/safety_validator.py`

**Responsabilidad:**
- Revisar la respuesta del Orchestrator ANTES de enviarla al usuario
- Validar 4 aspectos cr√≠ticos:
  1. **Fallo L√≥gico**: ¬øCita datos que no est√°n en Excel o state?
  2. **Seguridad**: ¬øRevela datos sensibles a personas no autorizadas?
  3. **Accesibilidad**: ¬øLenguaje demasiado complejo para el perfil del usuario?
  4. **Consistencia**: ¬øSe despide sin confirmar datos de la cita?
- Retornar "APPROVED" o "REJECTED" con correcci√≥n

**Estructura b√°sica:**

```python
from typing import Dict, Any
import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from src.infrastructure.config.settings import settings
from src.agent.prompts.safety_validator_prompt import build_safety_validation_prompt
import logging

logger = logging.getLogger(__name__)

MAX_VALIDATION_ATTEMPTS = 3

def safety_validator(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Agente de Seguridad (The Guardrail): Valida respuesta antes de enviarla.

    OUTPUT (JSON):
    {
        "status": "APPROVED | REJECTED",
        "issues": [lista de problemas detectados],
        "correction_needed": "Descripci√≥n de la correcci√≥n" (si REJECTED)
    }
    """

    print(f"\n{'‚îÅ'*80}")
    print(f"üõ°Ô∏è  [AGENTE C] THE GUARDRAIL - Validaci√≥n de Seguridad")
    print(f"{'‚îÅ'*80}")

    # Obtener respuesta del Orchestrator
    agent_response = state.get("agent_response", "")
    next_phase = state.get("next_phase", "")
    current_phase = state.get("current_phase", "")

    # Incrementar contador de intentos
    validation_attempts = state.get("validation_attempt_count", 0) + 1
    state["validation_attempt_count"] = validation_attempts

    print(f"   üîç Intento de validaci√≥n: {validation_attempts}/{MAX_VALIDATION_ATTEMPTS}")
    print(f"   üí¨ Validando respuesta: '{agent_response[:80]}...'")

    # Si ya se agotaron los intentos, aprobar autom√°ticamente
    if validation_attempts > MAX_VALIDATION_ATTEMPTS:
        logger.warning(f"Max validation attempts reached, auto-approving")
        print(f"   ‚ö†Ô∏è  M√°ximo de intentos alcanzado, aprobando autom√°ticamente")
        state["safety_validation_status"] = "APPROVED"
        state["safety_issues_detected"] = []
        return state

    # Construir prompt de validaci√≥n
    validation_prompt = build_safety_validation_prompt(
        agent_response=agent_response,
        current_phase=current_phase,
        next_phase=next_phase,
        known_data=_extract_known_data(state),
        excel_data=_extract_excel_data(state)
    )

    try:
        # LLM call
        llm = ChatOpenAI(
            openai_api_key=settings.OPENAI_API_KEY,
            model=settings.OPENAI_MODEL,
            temperature=0.1,  # Muy bajo para validaci√≥n objetiva
            max_tokens=800,
            response_format={"type": "json_object"}
        )

        llm_messages = [
            SystemMessage(content=validation_prompt),
            HumanMessage(content=f"Valida esta respuesta: {agent_response}")
        ]

        print(f"   üß† Validando con {settings.OPENAI_MODEL}...")
        response = llm.invoke(llm_messages)
        validation_result = json.loads(response.content)

        status = validation_result.get("status", "APPROVED")
        issues = validation_result.get("issues", [])
        correction = validation_result.get("correction_needed", "")

        state["safety_validation_status"] = status
        state["safety_issues_detected"] = issues
        state["safety_rejection_reason"] = correction if status == "REJECTED" else None
        state["safety_correction_needed"] = correction if status == "REJECTED" else None

        if status == "APPROVED":
            print(f"\n‚úÖ [AGENTE C] VALIDACI√ìN APROBADA")
            print(f"{'‚îÅ'*80}\n")
        else:
            print(f"\n‚ùå [AGENTE C] VALIDACI√ìN RECHAZADA")
            print(f"   Problemas detectados:")
            for issue in issues:
                print(f"   ‚ùå {issue}")
            print(f"\n   üí° Correcci√≥n sugerida: {correction}")
            print(f"{'‚îÅ'*80}\n")

    except Exception as e:
        logger.error(f"Error en safety validation: {e}")
        # En caso de error, aprobar por defecto (fail-open)
        state["safety_validation_status"] = "APPROVED"
        state["safety_issues_detected"] = []

    return state


def _extract_known_data(state: Dict[str, Any]) -> Dict[str, Any]:
    """Extrae datos ya conocidos del state para validaci√≥n"""
    return {
        "patient_name": state.get("patient_full_name"),
        "document_number": state.get("patient_document_number"),
        "service_type": state.get("service_type"),
        "appointment_date": state.get("appointment_date"),
        "appointment_time": state.get("appointment_time"),
        "pickup_address": state.get("pickup_address"),
        "contact_name": state.get("contact_name"),
        "contact_relationship": state.get("contact_relationship"),
        "contact_age": state.get("contact_age"),
    }


def _extract_excel_data(state: Dict[str, Any]) -> Dict[str, Any]:
    """Extrae datos del Excel (si es outbound call)"""
    # Esta funci√≥n deber√≠a acceder a los datos cargados desde Excel
    # Por ahora retornar los mismos datos conocidos
    return _extract_known_data(state)
```

**Archivo de prompts a crear:** `src/agent/prompts/safety_validator_prompt.py`

```python
from typing import Dict, Any

def build_safety_validation_prompt(
    agent_response: str,
    current_phase: str,
    next_phase: str,
    known_data: Dict[str, Any],
    excel_data: Dict[str, Any]
) -> str:
    """Construye prompt para validaci√≥n de seguridad"""

    prompt = f"""Eres el Validador de Seguridad y Accesibilidad (The Guardrail).

Tu tarea es revisar la respuesta del agente ANTES de que llegue al usuario final.

**CONTEXTO:**
- Fase actual: {current_phase}
- Pr√≥xima fase: {next_phase}

**Datos conocidos del paciente/servicio (del state):**
"""

    for key, value in known_data.items():
        if value:
            prompt += f"- {key}: {value}\n"

    prompt += f"\n**Datos del Excel (para outbound calls):**\n"
    for key, value in excel_data.items():
        if value and value != known_data.get(key):
            prompt += f"- {key}: {value}\n"

    prompt += f"""

**VALIDACIONES OBLIGATORIAS:**

1. **Fallo L√≥gico:**
   - ¬øEl agente est√° citando una fecha/hora que NO est√° en los datos conocidos o Excel?
   - ¬øMenciona un servicio o direcci√≥n incorrecta?
   - ¬øHay contradicciones con la informaci√≥n previa?

2. **Seguridad:**
   - ¬øEst√° revelando datos sensibles (documento, direcci√≥n) a alguien NO autorizado?
   - Si contact_relationship existe y contact_age < 18, ¬øel agente pidi√≥ hablar con un adulto?
   - ¬øSe est√° identificando correctamente la persona autorizada?

3. **Accesibilidad:**
   - ¬øEl lenguaje es demasiado complejo o t√©cnico?
   - ¬øUsa t√©rminos m√©dicos sin explicar?
   - ¬øLas instrucciones son claras y entendibles?

4. **Consistencia:**
   - Si next_phase = "END" o "OUTBOUND_CLOSING": ¬øSe confirmaron todos los datos de la cita?
   - ¬øEl agente dio un resumen final antes de despedirse?
   - ¬øSe identific√≥ claramente con su nombre antes de cerrar?

**CRITERIOS DE RECHAZO:**

Devuelve status="REJECTED" si encuentras:
- Fechas/horas que NO coinciden con los datos conocidos
- Revelaci√≥n de datos sensibles a persona no autorizada
- Lenguaje excesivamente complejo (m√°s de 30 palabras por frase)
- Despedida sin resumen de confirmaci√≥n

**OUTPUT (JSON obligatorio):**
```json
{{
  "status": "APPROVED | REJECTED",
  "issues": ["lista de problemas detectados"],
  "correction_needed": "Descripci√≥n de qu√© debe corregirse" (solo si REJECTED)
}}
```

**EJEMPLO DE RECHAZO:**

Respuesta del agente: "Su cita es el 15 de enero a las 10:00 AM."
Datos conocidos: appointment_date = "2024-01-20"

Output:
```json
{{
  "status": "REJECTED",
  "issues": ["fallo_logico"],
  "correction_needed": "La fecha citada (15 de enero) no coincide con los datos del Excel (20 de enero). Corregir la fecha en la respuesta."
}}
```

**IMPORTANTE:**
- Si no encuentras problemas, devuelve status="APPROVED" con issues=[]
- Si encuentras problemas, s√© espec√≠fico en la correcci√≥n necesaria
- Prioriza la seguridad sobre la cortes√≠a
"""

    return prompt
```

---

## 4. MODIFICACI√ìN DEL FLUJO DEL GRAFO

### Archivo: `src/agent/graph/conversation_graph.py`

**CAMBIOS:**

1. **Importar nuevos nodos:**

```python
from src.agent.graph.nodes import (
    input_processor,
    policy_engine_node,
    eligibility_checker,
    escalation_detector,
    context_emotion_analyzer,  # NUEVO
    context_builder,
    orchestrator,  # NUEVO (reemplaza llm_responder)
    safety_validator,  # NUEVO
    response_processor,
    state_updater,
    special_case_handler,
    excel_writer
)
```

2. **Agregar nodos al grafo:**

```python
# Despu√©s de escalation_detector, ANTES de context_builder
graph.add_node("context_emotion_analyzer", context_emotion_analyzer)

# Reemplazar llm_responder con orchestrator
graph.add_node("orchestrator", orchestrator)

# Despu√©s de orchestrator, ANTES de response_processor
graph.add_node("safety_validator", safety_validator)
```

3. **Modificar edges:**

```python
# Flujo normal despu√©s de no-escalaci√≥n:
graph.add_conditional_edges(
    "escalation_detector",
    should_escalate,
    {
        "special_case_handler": "special_case_handler",
        "context_emotion_analyzer": "context_emotion_analyzer"  # CAMBIO: antes iba a context_builder
    }
)

# Despu√©s de emotion analyzer ‚Üí context builder
graph.add_edge("context_emotion_analyzer", "context_builder")

# Despu√©s de context builder ‚Üí orchestrator (antes era llm_responder)
graph.add_edge("context_builder", "orchestrator")

# Despu√©s de orchestrator ‚Üí safety validator (NUEVO)
graph.add_edge("orchestrator", "safety_validator")

# Despu√©s de safety validator ‚Üí conditional routing
graph.add_conditional_edges(
    "safety_validator",
    route_after_safety_validation,  # NUEVA funci√≥n de routing
    {
        "orchestrator": "orchestrator",  # Si REJECTED, loop back
        "response_processor": "response_processor"  # Si APPROVED, continuar
    }
)

# El resto del flujo sigue igual
graph.add_conditional_edges(
    "response_processor",
    route_after_llm,
    {
        "excel_writer": "excel_writer",
        "special_case_handler": "special_case_handler",
        "state_updater": "state_updater"
    }
)
```

---

### Archivo: `src/agent/graph/edges/routing.py`

**AGREGAR NUEVA FUNCI√ìN:**

```python
def route_after_safety_validation(state: Dict[str, Any]) -> Literal['orchestrator', 'response_processor']:
    """
    Post-Safety Validation: Si REJECTED, volver a orchestrator. Si APPROVED, continuar.
    """
    validation_status = state.get('safety_validation_status', 'APPROVED')

    if validation_status == 'REJECTED':
        # Volver al orchestrator para regenerar respuesta
        return 'orchestrator'

    # Continuar con response_processor
    # Resetear contador de validaci√≥n
    state['validation_attempt_count'] = 0
    return 'response_processor'
```

---

## 5. MODIFICACI√ìN DE NODOS EXISTENTES

### 5.1. Context Builder

**Archivo:** `src/agent/graph/nodes/context_builder.py`

**CAMBIOS MENORES:**
- Ya no necesita hacer an√°lisis emocional (lo hace el nuevo nodo)
- Solo construir el prompt base con pol√≠ticas y casos
- El orchestrator enriquecer√° el prompt con adaptaciones emocionales

**NO REQUIERE CAMBIOS SIGNIFICATIVOS** - El nodo actual ya funciona bien.

---

### 5.2. Response Processor

**Archivo:** `src/agent/graph/nodes/response_processor.py`

**AGREGAR:**

```python
# Al inicio de la funci√≥n, despu√©s de obtener extracted
print(f"\n{'‚îÅ'*80}")
print(f"üìä [NODO 3/3] RESPONSE PROCESSOR - Procesando y Extrayendo Datos")
print(f"{'‚îÅ'*80}")

# Al final, antes del return
# Resetear validaci√≥n si la fase cambi√≥ exitosamente
if state.get("current_phase") != prev_phase:
    state["validation_attempt_count"] = 0
    state["safety_validation_status"] = None
    state["safety_correction_needed"] = None

print(f"‚úÖ [NODO 3/3] Datos procesados y fase actualizada")
print(f"   üîÑ {prev_phase} ‚Üí {state['current_phase']}")
print(f"{'‚îÅ'*80}\n")
```

---

## 6. MODIFICACI√ìN DE ARCHIVOS DE EXPORTACI√ìN

### Archivo: `src/agent/graph/nodes/__init__.py`

**AGREGAR NUEVOS NODOS:**

```python
from src.agent.graph.nodes.context_emotion_analyzer import context_emotion_analyzer
from src.agent.graph.nodes.orchestrator import orchestrator
from src.agent.graph.nodes.safety_validator import safety_validator

__all__ = [
    # ... existentes ...
    "context_emotion_analyzer",
    "orchestrator",
    "safety_validator",
]
```

---

## 7. L√ìGICA DE NEGOCIO ESPEC√çFICA POR FASE

### Implementaci√≥n en `orchestrator_prompt.py`

**AGREGAR SECCI√ìN ESPEC√çFICA POR FASE:**

```python
def build_orchestrator_prompt(...):
    # ... c√≥digo existente ...

    # Agregar l√≥gica espec√≠fica por fase
    enriched_prompt += f"\n\n{'='*80}\n"
    enriched_prompt += f"## L√ìGICA DE NEGOCIO PARA FASE: {current_phase}\n"
    enriched_prompt += f"{'='*80}\n\n"

    if current_phase == "OUTBOUND_GREETING":
        enriched_prompt += """
**FASE 1: Identificaci√≥n e Identidad (Prioridad M√°xima)**

1. Comparar nombre de quien habla con "Persona Autorizada" en Excel:
   - Si contact_age < 18 (menor de edad):
     ‚Üí "Por favor, ¬øme comunicas con un adulto responsable?"
     ‚Üí NO continuar hasta hablar con adulto

   - Si contact_name != patient_name y no es persona autorizada:
     ‚Üí "Por seguridad, debo hablar con [Nombre del Paciente]. ¬øSe encuentra?"
     ‚Üí Si NO est√°: Agendar nota "Llamar luego" y cerrar (next_phase = "OUTBOUND_CLOSING")

   - Si es persona autorizada:
     ‚Üí Continuar a next_phase = "OUTBOUND_LEGAL_NOTICE"

2. Extraer datos:
   - contact_name (nombre de quien habla)
   - contact_relationship (parentesco)
   - contact_age (edad) - CR√çTICO para detectar menores
"""

    elif current_phase == "OUTBOUND_LEGAL_NOTICE":
        enriched_prompt += """
**FASE 2: Presentaci√≥n Institucional**

Script din√°mico OBLIGATORIO:
"Habla {agent_name} de {company_name}. Le informo que por su seguridad esta llamada es grabada."

- Solo tras confirmar identidad
- Continuar a next_phase = "OUTBOUND_SERVICE_CONFIRMATION"
"""

    elif current_phase == "OUTBOUND_SERVICE_CONFIRMATION":
        enriched_prompt += """
**FASE 3: Motivo y Gesti√≥n de Cita**

1. Extraer fecha, hora, lugar del Excel (ya en el contexto)
2. Confirmar datos:
   "Le confirmo su cita de {service_type} el {appointment_date} a las {appointment_time}.
   Pasaremos a recogerle en {pickup_address}."

3. Detecci√≥n de Cambios:
   - Si usuario dice "ya no puedo ir", "necesito cambiar", "tengo que cancelar":
     ‚Üí Clasificar como "Cambio/Cancelaci√≥n"
     ‚Üí Extraer: special_observation con el motivo
     ‚Üí next_phase = "OUTBOUND_SPECIAL_CASES"

   - Si confirma sin problemas:
     ‚Üí next_phase = "OUTBOUND_CLOSING"
"""

    elif current_phase == "INCIDENT_MANAGEMENT" or "queja" in last_user_message.lower():
        enriched_prompt += """
**FASE 4: Manejo de Quejas (Empat√≠a Activa)**

Si el Agente Secundario detect√≥ Ira o Ansiedad:

1. PAUSAR el flujo de datos
2. Usar frase de validaci√≥n emocional:
   "Entiendo su frustraci√≥n, Sr./Sra. {nombre}, perm√≠tame ver c√≥mo podemos solucionar esto..."

3. Escuchar el problema sin interrumpir
4. Registrar queja:
   - extracted["incident_summary"] = "resumen de la queja"

5. Ofrecer soluci√≥n o escalaci√≥n si no est√° en tu alcance
"""

    elif current_phase == "OUTBOUND_CLOSING" or next_phase == "END":
        enriched_prompt += """
**FASE 5: Despedida y Cierre (Garant√≠a de Conformidad)**

üö® REGLA CR√çTICA: NO cerrar sin Resumen Final

Script OBLIGATORIO:
"Para confirmar: su cita de {service_type} es el {appointment_date} a las {appointment_time}.
Pasaremos a recogerle en {pickup_address}. ¬øLa informaci√≥n es clara?
Habl√≥ con {agent_name} de {company_name}. ¬°Que tenga buen d√≠a!"

- Verificar que TODOS los datos est√©n confirmados
- Identificarte con tu nombre
- Despedida cordial
- next_phase = "END"
"""

    return enriched_prompt
```

---

## 8. MEMORIA EMOCIONAL Y THREAD_ID

### 8.1. Persistencia de Emotional Memory

**Archivo:** `src/agent/langgraph_orchestrator.py` (o donde se maneje la persistencia)

**MODIFICAR:** Asegurar que `emotional_memory` se guarde en Redis junto con el resto del state.

```python
# Cuando se guarde el state en Redis:
state_to_save = {
    # ... campos existentes ...
    "emotional_memory": state.get("emotional_memory", []),
    "current_sentiment": state.get("current_sentiment"),
    "current_conflict_level": state.get("current_conflict_level"),
    "personality_mode": state.get("personality_mode", "Balanceado"),
    # ... etc
}
```

### 8.2. Thread_id para Sesiones Interrumpidas

**IDEA:** LangGraph ya soporta `thread_id` para persistencia de conversaciones. Si la llamada se corta y se retoma:

1. Usar el mismo `session_id` como `thread_id`
2. LangGraph cargar√° autom√°ticamente el estado completo (incluido emotional_memory)
3. El agente sabr√° exactamente en qu√© fase se qued√≥

**IMPLEMENTACI√ìN:**

En `langgraph_orchestrator.py`:

```python
# Al invocar el grafo
config = {
    "configurable": {
        "thread_id": session_id  # Usar session_id como thread_id
    }
}

result = graph.invoke(input_state, config=config)
```

Esto permitir√°:
- Si la llamada se corta en OUTBOUND_SERVICE_CONFIRMATION
- El usuario vuelve a llamar con el mismo `session_id`
- El grafo retoma desde OUTBOUND_SERVICE_CONFIRMATION
- Mantiene el historial emocional completo

---

## 9. VALIDACI√ìN EN CASCADA

### Flujo de Validaci√≥n con L√≠mite de Intentos

```
Orchestrator (genera respuesta)
    ‚Üì
Safety Validator (valida)
    ‚Üì
¬øAPPROVED?
    ‚îú‚îÄ S√ç ‚Üí Response Processor ‚Üí Continuar
    ‚îî‚îÄ NO ‚Üí ¬øIntentos < 3?
            ‚îú‚îÄ S√ç ‚Üí Orchestrator (regenerar con correction)
            ‚îî‚îÄ NO ‚Üí Auto-aprobar y continuar (evitar loop infinito)
```

**YA IMPLEMENTADO EN:** `safety_validator.py` (ver secci√≥n 3.3)

---

## 10. TESTING Y VALIDACI√ìN

### Tests a Crear/Modificar

1. **Tests unitarios para nuevos nodos:**
   - `tests/unit/agent/graph/nodes/test_context_emotion_analyzer.py`
   - `tests/unit/agent/graph/nodes/test_orchestrator.py`
   - `tests/unit/agent/graph/nodes/test_safety_validator.py`

2. **Tests de integraci√≥n:**
   - `tests/integration/test_multi_agent_flow.py`: Validar flujo completo con 3 agentes
   - `tests/integration/test_emotional_memory_persistence.py`: Validar persistencia de memoria emocional
   - `tests/integration/test_validation_cascade.py`: Validar loop de rechazo/aprobaci√≥n

3. **Tests E2E:**
   - Escenario 1: Usuario frustrado ‚Üí Validaci√≥n emocional activada
   - Escenario 2: Menor de edad contesta ‚Üí Protocolo de persona autorizada
   - Escenario 3: Guardrail rechaza respuesta ‚Üí Re-generaci√≥n exitosa
   - Escenario 4: Usuario confundido ‚Üí Modo simplificado activado

---

## 11. PLAN DE IMPLEMENTACI√ìN (Fases)

### Fase 1: Infraestructura Base (2-3 d√≠as)
1. Modificar `ConversationState` con nuevos campos
2. Crear prompts base para los 3 agentes
3. Actualizar persistencia en Redis

### Fase 2: Agentes Individuales (3-4 d√≠as)
1. Implementar Context & Emotion Manager
2. Implementar The Orchestrator (refactorizar llm_responder)
3. Implementar The Guardrail
4. Tests unitarios de cada agente

### Fase 3: Integraci√≥n del Grafo (2-3 d√≠as)
1. Modificar `conversation_graph.py` con nuevo flujo
2. Agregar routing para validaci√≥n en cascada
3. Tests de integraci√≥n del flujo completo

### Fase 4: L√≥gica de Negocio (2-3 d√≠as)
1. Implementar l√≥gica espec√≠fica por fase
2. Protocolo de menores de edad
3. Validaci√≥n de persona autorizada
4. Resumen final obligatorio

### Fase 5: Testing y Ajustes (3-4 d√≠as)
1. Tests E2E con escenarios complejos
2. Ajuste de prompts seg√∫n resultados
3. Validaci√≥n de memoria emocional
4. Pruebas con llamadas reales simuladas

**TIEMPO ESTIMADO TOTAL:** 12-17 d√≠as de desarrollo

---

## 12. ARCHIVOS RESUMEN

### Archivos a CREAR:
1. `src/agent/graph/nodes/context_emotion_analyzer.py`
2. `src/agent/graph/nodes/orchestrator.py`
3. `src/agent/graph/nodes/safety_validator.py`
4. `src/agent/prompts/emotion_analyzer_prompt.py`
5. `src/agent/prompts/orchestrator_prompt.py`
6. `src/agent/prompts/safety_validator_prompt.py`
7. `tests/unit/agent/graph/nodes/test_context_emotion_analyzer.py`
8. `tests/unit/agent/graph/nodes/test_orchestrator.py`
9. `tests/unit/agent/graph/nodes/test_safety_validator.py`
10. `tests/integration/test_multi_agent_flow.py`
11. `tests/integration/test_emotional_memory_persistence.py`
12. `tests/integration/test_validation_cascade.py`

### Archivos a MODIFICAR:
1. `src/agent/graph/state.py` - Agregar campos emocionales y de validaci√≥n
2. `src/agent/graph/conversation_graph.py` - Modificar flujo del grafo
3. `src/agent/graph/edges/routing.py` - Agregar routing de validaci√≥n
4. `src/agent/graph/nodes/__init__.py` - Exportar nuevos nodos
5. `src/agent/graph/nodes/response_processor.py` - Resetear validaci√≥n
6. `src/agent/langgraph_orchestrator.py` - Persistencia de emotional_memory
7. `src/infrastructure/persistence/redis/session_store.py` - Guardar nuevos campos (si es necesario)

---

## 13. DEPENDENCIAS Y CONSIDERACIONES

### Dependencias Nuevas:
- **Ninguna nueva**: Usamos las mismas bibliotecas (LangChain, OpenAI, LangGraph)

### Consideraciones de Costos:
- **3 llamadas LLM por turno** (emotion_analyzer + orchestrator + safety_validator)
- Mitigaci√≥n:
  - emotion_analyzer: temperatura 0.3, max_tokens 500 (r√°pido y barato)
  - safety_validator: temperatura 0.1, max_tokens 800 (barato)
  - orchestrator: temperatura normal, max_tokens 1500 (m√°s costoso pero es el principal)
- **Estimaci√≥n:** ~2.5x costo actual por turno

### Consideraciones de Latencia:
- **Latencia adicional:** ~1-2 segundos por turno (2 LLM calls extra)
- Mitigaci√≥n:
  - Usar `gpt-4o-mini` para emotion_analyzer y safety_validator (m√°s r√°pido)
  - Usar `gpt-4-turbo` solo para orchestrator

---

## 14. M√âTRICAS DE √âXITO

### KPIs para Validar la Migraci√≥n:
1. **Adaptaci√≥n emocional:**
   - % de usuarios frustrados que recibieron validaci√≥n emocional
   - Tiempo promedio de resoluci√≥n de quejas

2. **Seguridad:**
   - % de respuestas rechazadas por el Guardrail
   - % de datos sensibles protegidos correctamente

3. **Calidad de respuestas:**
   - % de despedidas con resumen final
   - % de protocolos de menores aplicados correctamente

4. **Performance:**
   - Latencia promedio por turno
   - Costo promedio por conversaci√≥n

---

## CONCLUSI√ìN

Esta migraci√≥n transforma el sistema de mono-agente a multi-agente con:
- **An√°lisis emocional inteligente** (Context & Emotion Manager)
- **Respuestas adaptadas al contexto** (The Orchestrator)
- **Validaci√≥n de seguridad autom√°tica** (The Guardrail)
- **Memoria emocional persistente**
- **Validaci√≥n en cascada con auto-correcci√≥n**

El resultado ser√° un agente m√°s emp√°tico, seguro y consistente, alineado con las mejores pr√°cticas de atenci√≥n al cliente y cumplimiento normativo.
