"""
Simple Analyzer - An√°lisis basado en reglas (sin LLM).

Reemplaza el pre_analyzer LLM por un an√°lisis r√°pido basado en patrones.
Reduce la latencia de ~2 segundos a <10ms.
"""
import re
from typing import Dict, Any, List

# Patrones de emoci√≥n
EMOTION_PATTERNS = {
    "frustraci√≥n": [
        r"\b(molest[oa]?|enojad[oa]?|furi[oa]?|hart[oa]?|cansad[oa]?)\b",
        r"\b(increible|incre√≠ble|absurdo|ridiculo|rid√≠culo|inaceptable)\b",
        r"\b(no me gusta|estoy molest|que problema|qu√© problema|siempre lo mismo|ya van varias)\b",
        r"[!]{2,}",  # M√∫ltiples signos de exclamaci√≥n
        r"\b(mal servicio|pesimo|p√©simo|terrible|horrible)\b",
    ],
    "confusi√≥n": [
        r"\b(no entiendo|no entendi|no entend√≠|como asi|c√≥mo as√≠)\b",
        r"\b(que significa|qu√© significa|puede repetir|no me queda claro)\b",
        r"\b(expliqueme|expl√≠queme|no se|no s√©|cual es|cu√°l es|que es|qu√© es)\b",
        r"[?]{2,}",  # M√∫ltiples signos de interrogaci√≥n
    ],
    "positivo": [
        r"\b(gracias|excelente|perfecto|muy bien|genial|maravilloso|fantastico|fant√°stico)\b",
        r"\b(agradezco|amable|claro|entendido|listo)\b",
    ],
}

# Patrones de intenci√≥n
INTENT_PATTERNS = {
    "confirmar": [
        r"^(s√≠|si|claro|ok|okay|vale|listo|correcto|afirmativo|as√≠ es|exacto|eso)$",
        r"\b(confirmo|acepto|de acuerdo|est√° bien)\b",
    ],
    "negar": [
        r"^(no|nop|nel|negativo)$",
        r"\b(no puedo|no quiero|no me sirve|no asistir)\b",
    ],
    "cambiar": [
        r"\b(cambiar|modificar|actualizar|diferente|otra|otro)\b",
        r"\b(cambio de|quiero cambiar|necesito cambiar)\b",
    ],
    "cancelar": [
        r"\b(cancelar|anular|no voy|no asistir|no puedo ir)\b",
    ],
    "queja": [
        r"\b(queja|reclamo|denunciar|reportar|mal servicio)\b",
        r"\b(el conductor|lleg√≥ tarde|no lleg√≥|me dej√≥)\b",
    ],
    "pregunta": [
        r"^\s*¬ø",  # Empieza con signo de pregunta
        r"\b(cuando|cu√°ndo|donde|d√≥nde|como|c√≥mo|cual|cu√°l)\b",
        r"\b(que hora|qu√© hora|a que|a qu√©|por que|por qu√©)\b",
        r"\?$",  # Termina con signo de pregunta
    ],
    "saludo": [
        r"^(hola|buenos dias|buenos d√≠as|buenas tardes|buenas noches|alo|al√≥)[\s,!.]*$",
        r"^(hola|buenos dias|buenos d√≠as|buenas tardes|buenas noches)",
    ],
}

# Patrones de t√≥pico
TOPIC_PATTERNS = {
    "horario": [
        r"\b(hora|horario|tiempo|tarde|temprano|puntual|demora)\b",
    ],
    "direccion": [
        r"\b(direcci√≥n|direccion|calle|carrera|avenida|barrio|casa|apartamento)\b",
        r"\b(recoger|recogida|paso por)\b",
    ],
    "conductor": [
        r"\b(conductor|chofer|ch√≥fer|driver|quien conduce|el que maneja)\b",
    ],
    "fecha": [
        r"\b(fecha|d√≠a|dia|ma√±ana|pasado ma√±ana|lunes|martes|mi√©rcoles|jueves|viernes)\b",
    ],
    "servicio": [
        r"\b(servicio|transporte|cita|terapia|di√°lisis|dialisis)\b",
    ],
}

# Keywords que activan pol√≠ticas
POLICY_KEYWORDS_PATTERNS = {
    "cambio_direccion": [r"\b(cambiar direcci√≥n|otra direcci√≥n|no es esa|direcci√≥n incorrecta)\b"],
    "zona_cobertura": [r"\b(vereda|rural|fuera de|zona|cobertura|lejos)\b"],
    "acompanante": [r"\b(acompa√±ante|acompa√±ar|ir con|familiar|hijo|esposa)\b"],
    "conductor": [r"\b(conductor espec√≠fico|mismo conductor|prefiero|no quiero ese)\b"],
    "menor_edad": [r"\b(soy el hijo|soy la hija|tengo \d+ a√±os|menor)\b"],
}


def analyze_message(message: str) -> Dict[str, Any]:
    """
    Analiza un mensaje usando patrones regex.

    Retorna el mismo formato que el pre_analyzer LLM pero sin latencia.

    Args:
        message: Mensaje del usuario

    Returns:
        Dict con: emotion, emotion_level, intent, topic, needs_empathy, policy_keywords
    """
    msg_lower = message.lower().strip()

    # Detectar emoci√≥n
    emotion = "neutro"
    emotion_level = "bajo"

    for emo, patterns in EMOTION_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, msg_lower, re.IGNORECASE):
                emotion = emo
                # Determinar nivel
                matches = sum(1 for p in patterns if re.search(p, msg_lower, re.IGNORECASE))
                if matches >= 3:
                    emotion_level = "alto"
                elif matches >= 2:
                    emotion_level = "medio"
                else:
                    emotion_level = "bajo"
                break
        if emotion != "neutro":
            break

    # Detectar intenci√≥n
    intent = "otro"
    for int_name, patterns in INTENT_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, msg_lower, re.IGNORECASE):
                intent = int_name
                break
        if intent != "otro":
            break

    # Detectar t√≥pico
    topic = "otro"
    for top_name, patterns in TOPIC_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, msg_lower, re.IGNORECASE):
                topic = top_name
                break
        if topic != "otro":
            break

    # Detectar keywords de pol√≠tica
    policy_keywords = []
    for keyword, patterns in POLICY_KEYWORDS_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, msg_lower, re.IGNORECASE):
                policy_keywords.append(keyword)
                break

    # Determinar si necesita empat√≠a
    needs_empathy = emotion in ["frustraci√≥n", "confusi√≥n"] and emotion_level in ["medio", "alto"]

    return {
        "emotion": emotion,
        "emotion_level": emotion_level,
        "intent": intent,
        "topic": topic,
        "needs_empathy": needs_empathy,
        "policy_keywords": policy_keywords,
    }


def simple_analyzer_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Nodo de LangGraph para an√°lisis simple basado en reglas.

    Reemplaza pre_analyzer_node pero sin llamada LLM.
    Latencia: <10ms en lugar de ~2000ms.
    """
    import time
    import logging
    logger = logging.getLogger(__name__)

    start_time = time.perf_counter()

    print("\n" + "="*60)
    print("‚ö° [SIMPLE_ANALYZER] AN√ÅLISIS R√ÅPIDO (sin LLM)")
    print("="*60)

    # Obtener √∫ltimo mensaje del usuario
    messages = state.get("messages", [])
    last_message = ""
    for msg in reversed(messages):
        if isinstance(msg, dict) and msg.get("role") == "user":
            last_message = msg.get("content", "")
            break
        elif hasattr(msg, "type") and msg.type == "human":
            last_message = msg.content
            break

    if not last_message:
        # Sin mensaje, valores por defecto
        state["user_emotion"] = "neutro"
        state["user_emotion_level"] = "bajo"
        state["user_intent"] = "otro"
        state["user_topic"] = "otro"
        state["needs_empathy"] = False
        state["policy_keywords"] = []
        print("   (sin mensaje de usuario)")
        print("="*60 + "\n")
        return state

    # Analizar con reglas
    analysis = analyze_message(last_message)

    # Agregar al state
    state["user_emotion"] = analysis["emotion"]
    state["user_emotion_level"] = analysis["emotion_level"]
    state["user_intent"] = analysis["intent"]
    state["user_topic"] = analysis["topic"]
    state["needs_empathy"] = analysis["needs_empathy"]
    state["policy_keywords"] = analysis["policy_keywords"]

    # Calcular tiempo
    elapsed_ms = (time.perf_counter() - start_time) * 1000

    logger.info(f"[SIMPLE_ANALYZER] {analysis['emotion']}({analysis['emotion_level']}) | {analysis['intent']} | {analysis['topic']} | {elapsed_ms:.1f}ms")

    print(f"\nüìä [SIMPLE_ANALYZER] RESULTADO:")
    print(f"   ‚Ä¢ Emoci√≥n: {analysis['emotion']} ({analysis['emotion_level']})")
    print(f"   ‚Ä¢ Intent: {analysis['intent']}")
    print(f"   ‚Ä¢ Topic: {analysis['topic']}")
    print(f"   ‚Ä¢ Needs empathy: {analysis['needs_empathy']}")
    print(f"   ‚Ä¢ Policy keywords: {analysis['policy_keywords']}")
    print(f"   ‚è±Ô∏è  Tiempo: {elapsed_ms:.1f}ms (antes ~2000ms con LLM)")
    print("="*60 + "\n")

    return state
